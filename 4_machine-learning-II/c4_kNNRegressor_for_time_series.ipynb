{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can the KNeighborsRegressor be used for time series forecasting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will learn how to make time-series predictions with the *KNeighborsRegressor* model, the regression variant of the *k*-NN algorithm.\n",
    "\n",
    "We will work with the Airline Passengers dataset, which provides the monthly number of airline passengers from 1949-1960 for an airline company. This dataset is available on Kaggle and can be downloaded [here](https://www.kaggle.com/abhishekmamidi/air-passengers#AirPassengers.csv). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and create a datetime index\n",
    "data = pd.read_csv(\"c4_AirPassengers.csv\", index_col=\"Month\", parse_dates=True)\n",
    "\n",
    "# Rename columns for convenience\n",
    "data.columns = [\"Passengers\"]\n",
    "data.index.names = [\"Date\"]\n",
    "\n",
    "# Print the shape of the dataframe\n",
    "print(\"Data shape: {}\".format(data.shape))\n",
    "\n",
    "# Print a few samples\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a first look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the converters\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the number of passengers\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "font_dict = {\"fontname\": \"Arial\", \"size\": \"14\"}\n",
    "\n",
    "plt.plot(data[\"Passengers\"])\n",
    "plt.xlabel(\"Year\", fontdict=font_dict)\n",
    "plt.ylabel(\"Monthly passengers (in thousands)\", fontdict=font_dict)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new colum: year\n",
    "data[\"year\"] = data.index.year\n",
    "\n",
    "# Group by the 'year' and generate descriptive statistics\n",
    "data.groupby(\"year\").describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the plot of the time-series and the table from above, we observe:  \n",
    "* an increasing *trend*, as the *mean* number of passengers increases with time. For example, the mean number of passengers in 1949 is approximately 127. Six years later, in 1955, the average number of passengers has doubled (284) and, in 1960, is has almost quadrupled (476).\n",
    "* a *seasonal pattern*, as summer months are more popular than winter months,\n",
    "* that the annual variation in the data increases with time. In 1949, the number of passengers ranges from 104 to 148 (i.e., a total variation of 44 passengers), while in 1960, the total variation is 232 passengers!\n",
    "\n",
    "We need to build forecasting models that take into account the trend, the seasonal pattern, and the increasing variation in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove column: 'year'\n",
    "data.drop(\"year\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data transformation\n",
    "\n",
    "The variation in the magnitude of the time-series with time is referred to as *non-stationarity in the variance*. Non-constant variance is common in time-series data, and we need to account for it before building our models, as this will help to improve predictions. \n",
    "\n",
    "One way of stabilizing the variance is by applying a logarithm transformation to the target. Log-transforming the number of passengers will help to \"stabilize\" the annual variation in the data to form a time-series that has a variance approximately constant over time.\n",
    "\n",
    "However, there is no \"one-size-fits-all\" solution for all data; other types of transformations (inverse, square root, cubic root, etc.) may work better in other cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-transform 'Passengers'\n",
    "data[\"Passengers\"] = np.log(data[\"Passengers\"])\n",
    "\n",
    "# Print the head of the DataFrame\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the log-transformed 'Passengers'\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "plt.plot(data[\"Passengers\"])\n",
    "plt.xlabel(\"Year\", fontdict=font_dict)\n",
    "plt.ylabel(\"Log-Passengers\", fontdict=font_dict)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the log-transformation has helped to reduce the variation in size of the annual cycles in time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a first model\n",
    "\n",
    "We will now to use *KNeighborsRegressor* to build a model that predicts the number of passengers in the next month. Before fitting our first model, let's have a look at the data once more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering: the *Time* feature\n",
    "\n",
    "At the moment, *Date* is expressed in a \"year-month-day\" format, which is not very convenient as it cannot be \"processed\" by the model. \n",
    "\n",
    "Let's create a new feature *Time* that is equal to the number of months since the first timestamp in the data (January 1, 1949)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New feature: 'Time'\n",
    "\n",
    "data[\"Time\"] = np.arange(0, data.shape[0])\n",
    "\n",
    "# Print the head of the DataFrame\n",
    "data[[\"Time\", \"Passengers\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training/test splitting for time-series data\n",
    "\n",
    "We will now split into train, and test sets. We need to make sure that the test set covers a later period in time from the training set, to prevent any information about the future from \"leaking\" into the model during training. In this example, we will use the samples from 1949 to 1959 as our training set, and the last year in the data as our test set (1960).\n",
    "\n",
    "Below, we define a function to split the data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to split the data into training and test sets\n",
    "\n",
    "\n",
    "def train_test_split(df, start_dt):\n",
    "\n",
    "    \"\"\"\n",
    "    This function performs train/test splitting for time-series data.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    - df        : the data (features & target)\n",
    "    - start_df  : the starting date for the test set\n",
    "\n",
    "    Outputs\n",
    "    -------\n",
    "    - X_tr,y_tr : X/y arrays for train set\n",
    "    - X_te,y_te : X/y arrays for test data\n",
    "    \"\"\"\n",
    "\n",
    "    # Train set\n",
    "    X_tr = df[df.index < test_start_dt].drop(\"Passengers\", axis=1).values\n",
    "    y_tr = df[df.index < test_start_dt][\"Passengers\"]\n",
    "\n",
    "    # Test set\n",
    "    X_te = df[df.index >= test_start_dt].drop(\"Passengers\", axis=1).values\n",
    "    y_te = df[df.index >= test_start_dt][\"Passengers\"]\n",
    "\n",
    "    print(\"Train set\")\n",
    "    print(\"---------\")\n",
    "    print(\"Features: {} Target: {}\\n\".format(X_tr.shape, y_tr.shape))\n",
    "\n",
    "    print(\"Test set\")\n",
    "    print(\"--------\")\n",
    "    print(\"Features: {} Target: {}\".format(X_te.shape, y_te.shape))\n",
    "\n",
    "    return (X_tr, X_te, y_tr, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train/test sets and create X/y arrays\n",
    "\n",
    "# Set the starting date of the test set: Jan 1st, 1960\n",
    "test_start_dt = \"1960-01-01\"\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, test_start_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the train/test sets\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "plt.plot(y_train, label=\"Training data\")\n",
    "plt.plot(y_test, label=\"Test data\")\n",
    "\n",
    "plt.xlabel(\"Year\", fontdict=font_dict)\n",
    "plt.ylabel(\"Log-Passengers\", fontdict=font_dict)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now fit *KNeighborsRegressor* and evaluate its performance using the Mean Absolute Error (MAE). The target *Passengers* is log-transformed. This means that we need to invert the log-transformed *Passengers* back to their original scale before computing the error of the model. We can invert log-transformations using Numpy's exponential function (*numpy.exp*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Absolute error (MAE)\n",
    "def MAE(y, y_pred):\n",
    "    return np.mean(np.abs(y - y_pred))\n",
    "\n",
    "\n",
    "# Invert log-transformation and compute model error\n",
    "def model_error(y, y_pred):\n",
    "    score = MAE(np.exp(y), np.exp(y_pred))  # Invert log-transformation and compute MAE\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Create and fit a KNeighborsRegressor model\n",
    "knn = KNeighborsRegressor(\n",
    "    n_neighbors=3, p=1, weights=\"distance\"\n",
    ")  # Hyperparameters: tuned with GridSearchCV (not shown here)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Compute predictions on train/test sets\n",
    "y_pred_tr = knn.predict(X_train)\n",
    "y_pred_te = knn.predict(X_test)\n",
    "\n",
    "# Model performance\n",
    "print(\"Model 1\")\n",
    "print(\"-------\")\n",
    "print()\n",
    "print(\n",
    "    \"Train set - MAE score: {:.0f} passengers\".format(model_error(y_train, y_pred_tr))\n",
    ")\n",
    "print(\"Test set  - MAE score: {:.0f} passengers\".format(model_error(y_test, y_pred_te)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to plot predictions\n",
    "\n",
    "\n",
    "def plot_predictions(df, y_tr, y_te, y_pred_tr, y_pred_te, score_te):\n",
    "\n",
    "    \"\"\"\n",
    "    This function plots the training/test data along with the predictions\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    - y_tr, y_te           : target (train/test sets)\n",
    "    - y_pred_tr, y_pred_te : predictions (train/test sets)\n",
    "    - score_te             : model error (test set)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    font = {\"fontname\": \"Arial\", \"size\": \"14\"}\n",
    "    font_title = {\"fontname\": \"Arial\", \"size\": \"16\"}\n",
    "\n",
    "    plt.figure(figsize=(9, 6))\n",
    "\n",
    "    # True values\n",
    "    plt.plot(df.index[0 : len(y_tr)], np.exp(y_tr), label=\"train set\", color=\"black\")\n",
    "    plt.plot(\n",
    "        df.index[len(y_tr) : len(y_tr) + len(y_te)],\n",
    "        np.exp(y_te),\n",
    "        label=\"test set\",\n",
    "        color=\"grey\",\n",
    "    )\n",
    "\n",
    "    # Predictions\n",
    "    plt.plot(\n",
    "        df.index[0 : len(y_tr)],\n",
    "        np.exp(y_pred_tr),\n",
    "        label=\"predictions train\",\n",
    "        color=\"blue\",\n",
    "    )\n",
    "    plt.plot(\n",
    "        df.index[len(y_tr) : len(y_tr) + len(y_te)],\n",
    "        np.exp(y_pred_te),\n",
    "        \"-\",\n",
    "        label=\"predictions test\",\n",
    "        color=\"red\",\n",
    "    )\n",
    "\n",
    "    plt.xlabel(\"Year\", **font)\n",
    "    plt.ylabel(\"Monthly passengers (in thousands)\", **font)\n",
    "    plt.title(\n",
    "        \"MAE score: {:.0f} passengers (test set)\".format(score_te),\n",
    "        fontsize=14,\n",
    "        **font_title\n",
    "    )\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "\n",
    "plot_predictions(\n",
    "    data, y_train, y_test, y_pred_tr, y_pred_te, model_error(y_test, y_pred_te)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions for the training set are good. However, for the test set, the model predicted a continuous line.\n",
    "\n",
    "In the training data, the values of the *Time* feature range between 0 and 131, while in the test set they range between 132 and 143. The issue here is that *KNeighborsRegressor* cannot extrapolate to feature values outside the training set. As a result, for the test set, *KNeighborsRegressor* predicts the mean number of the passengers of the k-nearest neighbors from the training set, which are the last *3* timesteps in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a second model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how we can improve our model. We will remove the *Time* feature, and we will add two new features: the *month* and the *year*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering: the *Year* and *Month* features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new features: month and year\n",
    "data[\"Year\"] = data.index.year\n",
    "data[\"Month\"] = data.index.month\n",
    "\n",
    "# Remove column 'Time'\n",
    "data.drop(\"Time\", axis=1, inplace=True)\n",
    "\n",
    "data[[\"Month\", \"Year\", \"Passengers\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this second model, *Year* and *Month* are going to be the features and *Passengers* the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train/set sets and create X/y arrays\n",
    "\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(data, test_start_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a few samples from the training data\n",
    "\n",
    "X_train_2[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a few samples from the test data\n",
    "\n",
    "X_test_2[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will fit a second *KNeighborsRegressor* model and evaluate its performance using the Mean Absolute Error (MAE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a second KNeighborsRegressor model\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),  # Scaling improves performance\n",
    "        (\"knn\", KNeighborsRegressor(n_neighbors=3, p=2, weights=\"distance\")),\n",
    "    ]\n",
    ")  # Hyperparameters: tuned with GridSearchCV (not shown here)\n",
    "pipe.fit(X_train_2, y_train_2)\n",
    "\n",
    "# Compute predictions for train/test sets\n",
    "y_pred_tr_2 = pipe.predict(X_train_2)\n",
    "y_pred_te_2 = pipe.predict(X_test_2)\n",
    "\n",
    "# Model performance\n",
    "print(\"Model 2\")\n",
    "print(\"-------\")\n",
    "print()\n",
    "print(\n",
    "    \"Train set - MAE score: {:.0f} passengers\".format(\n",
    "        model_error(y_train_2, y_pred_tr_2)\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Test set  - MAE score: {:.0f} passengers\".format(\n",
    "        model_error(y_test_2, y_pred_te_2)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "\n",
    "plot_predictions(\n",
    "    data,\n",
    "    y_train_2,\n",
    "    y_test_2,\n",
    "    y_pred_tr_2,\n",
    "    y_pred_te_2,\n",
    "    model_error(y_test_2, y_pred_te_2),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions on the test set have improved, but we miss to capture the trend in the data. What this model is predicting at the moment is the mean number of passengers of the k-nearest neighbors in the training set. Unlike the first model, the k-nearest neighbors are now determined based on the month and year combination of the *k*-nearest neighbors in the training set, hence the improvement in the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a third model  \n",
    "\n",
    "Let's now see if we can further improve our model by eliminating the trend in the target. One way of removing the trend, i.e. the *non-stationarity in the mean*, is through *differencing*, which consists in computing the difference between consecutive observations. \n",
    "\n",
    "### Data preparation :: Differencing\n",
    "\n",
    "Differencing can be achieved with the *pandas.DataFrame.diff* function. *Pandas.DataFrame.diff* first moves the time-series forward one position and then computes the difference with the original time-series (all in 1-step)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the data\n",
    "data1 = data.copy()\n",
    "\n",
    "# Column \"Passengers\" : apply differencing\n",
    "data1[\"Passengers\"] = data1[\"Passengers\"].diff()\n",
    "\n",
    "# Show a few samples from the data\n",
    "data1[[\"Month\", \"Year\", \"Passengers\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the first difference of the time-series resulted in a missing value in the first entry of *Passengers*. We need to remove missing values from the data before fiting our third model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing values\n",
    "data1.dropna(inplace=True)\n",
    "\n",
    "# Show a few samples from the data\n",
    "data1[[\"Month\", \"Year\", \"Passengers\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the dataframe\n",
    "print(\"Data shape: {}\".format(data1.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the new feature 'Passengers'\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "plt.plot(data1[\"Passengers\"])\n",
    "\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Differenced Log-Passengers\", fontdict=font_dict)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the first difference of the *Passengers* returned a time-series of the month-to-month changes in the number of passengers, as shown above. We notice that differencing has helped to stabilize the mean value of the target *Passengers*.\n",
    "\n",
    "We are now ready to fit our third model; *Year* and *Month* are going to be the features and *Passengers* (differenced and log-transformed) the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train/set sets and create X/y arrays\n",
    "\n",
    "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(data1, test_start_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit KNeighborsRegressor\n",
    "\n",
    "# Here: better results without scaling\n",
    "knn3 = KNeighborsRegressor(\n",
    "    n_neighbors=2, p=1, weights=\"distance\"\n",
    ")  # Hyperparameters: tuned with GridSearchCV\n",
    "knn3.fit(X_train_3, y_train_3)\n",
    "\n",
    "# Compute predictions on train/test sets\n",
    "y_pred_tr_3 = knn3.predict(X_train_3)\n",
    "y_pred_te_3 = knn3.predict(X_test_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invert differencing\n",
    "\n",
    "Now, the target and the predictions are expressed as the month-to-month change in the number of passengers. We need to invert differencing to turn the target and the predictions back to their original scale before computing the error of the model.\n",
    "\n",
    "Differencing can be inverted using Numpy's cumulative sum function ([numpy.cumsum](https://numpy.org/doc/stable/reference/generated/numpy.cumsum.html)). However, differencing threw away the first entry of the target *Passengers*. So, before calling the *cumsum* function, we need to put this value back together with the predictions on the train and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to invert differencing\n",
    "\n",
    "\n",
    "def invert_differencing(y_tr, y_te, y0, len_train):\n",
    "\n",
    "    \"\"\"\n",
    "    This function inverts differencing of time-series data and\n",
    "    re-splits the data into training/test sets.\n",
    "\n",
    "    It takes the following arguments:\n",
    "    - y_tr      : predictions on the train data (differenced)\n",
    "    - y_te      : predictions on the test data (differenced)\n",
    "    - y0        : the first entry of the target (before differencing)\n",
    "    - len_train : number of samples in the training set (before differencing)\n",
    "\n",
    "    Output:\n",
    "    - y_train   : predictions of the train data (original scale)\n",
    "    - y_test    : predictions of the test data (original scale)\n",
    "    \"\"\"\n",
    "\n",
    "    y_tr_te_inv = np.r_[y0, y_tr, y_te].cumsum()  # Invert differencing\n",
    "    y_train, y_test = (\n",
    "        y_tr_te_inv[0:len_train],\n",
    "        y_tr_te_inv[len_train:],\n",
    "    )  # Train/test split\n",
    "\n",
    "    return (y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the first entry of the target which was thrown away after differencing\n",
    "y0 = data[\"Passengers\"][0]\n",
    "\n",
    "# Define the number of samples in the train data (before differencing)\n",
    "len_train = len(y_train)\n",
    "\n",
    "# Target: Invert differencing\n",
    "y_train_3, y_test_3 = invert_differencing(y_train_3, y_test_3, y0, len_train)\n",
    "\n",
    "# Predictions: Invert differencing\n",
    "y_pred_tr_3, y_pred_te_3 = invert_differencing(y_pred_tr_3, y_pred_te_3, y0, len_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model performance\n",
    "\n",
    "print(\"Model 3\")\n",
    "print(\"-------\")\n",
    "print()\n",
    "print(\n",
    "    \"Train set - MAE score: {:.0f} passengers\".format(\n",
    "        model_error(y_train_3, y_pred_tr_3)\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Test set  - MAE score: {:.0f} passengers\".format(\n",
    "        model_error(y_test_3, y_pred_te_3)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "\n",
    "plot_predictions(\n",
    "    data,\n",
    "    y_train_3,\n",
    "    y_test_3,\n",
    "    y_pred_tr_3,\n",
    "    y_pred_te_3,\n",
    "    model_error(y_test_3, y_pred_te_3),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a model that captures the periodic behavior and the trend in the number of airline passengers. This way, we managed to further improve model performance on the test set! \n",
    "\n",
    "In the last part of this exercise, we will introduce another type of feature that is commonly used in time-series prediction: *lag features*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a fourth model  \n",
    "\n",
    "### Feature engineering :: Lag features\n",
    "\n",
    "Time-series prediction models are often constructed using *lag features* as a means of incorporating information about the past into the model. Let's begin by discussing *how* to build *lag features*. \n",
    "\n",
    "If the observation at time t is $y_t$, then, the observation at the previous time-step is $y_{t-1}$, at the previous two time-steps $y_{t-2}$, and so on. We say that $y_{t-1}$ is *lagged* by one period, $y_{t-2}$ by two periods, etc. \n",
    "\n",
    "We can create *lag features* with the *pandas.DataFrame.shift* function using the *periods* keyword. Setting *periods=1* means that the time-series will be shifted forward one position and so on. Let's see how this works with an example.\n",
    "\n",
    "*Note*: We will be working with the *detrended* and *log-transformed* *Passengers* column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the data\n",
    "data2 = data1[[\"Month\", \"Year\", \"Passengers\"]].copy()\n",
    "\n",
    "# Show a few samples\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE\n",
    "# Create lag features: t-1 and t-2\n",
    "lags = pd.concat(\n",
    "    [\n",
    "        data2[\"Passengers\"].shift(periods=2),\n",
    "        data2[\"Passengers\"].shift(periods=1),\n",
    "        data2[\"Passengers\"],\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "lags.columns = [\"t-2\", \"t-1\", \"t\"]\n",
    "\n",
    "# Show a few samples\n",
    "lags.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column t corresponds to the (detrended and log-transformed) *Passengers* column. *t-1* corresponds to the *Passengers* column shifted forward by one period, and the *t-2* shifted forward by two periods. \n",
    "\n",
    "Shifting the time-series has resulted in missing values at the beginning of the lagged features, which we will remove below with the *dropna* method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing values\n",
    "lags.dropna(inplace=True)\n",
    "\n",
    "# Show a few samples\n",
    "lags.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we saw *how* to construct *lag features*. Let's now see how to select *meaningful* lag features. \n",
    "\n",
    "*Pandas.plotting.lag_plot* is a convenient tool for creating *lag plots* for time-series. Below, we use it to plot the *Passengers* column (*detrended* and *log-transformed*) against lagged features. Each graph shows $y_t$ plotted against $y_{t−lag}$, where *lag* ranges from 1 to 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lag plot of \"Passengers\"\n",
    "\n",
    "fig, axes = plt.subplots(2, 6, figsize=(18, 6))\n",
    "\n",
    "for lag, ax in zip(np.arange(1, 13), axes.ravel()):\n",
    "    pd.plotting.lag_plot(data2[\"Passengers\"], lag=lag, ax=ax, alpha=0.6)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that *Passengers* is correlated with lag 12; this is due to the seasonality in the data. The rest of the lags show no, or weak correlation with *Passengers*.\n",
    "\n",
    "In our last model, we will use *lag 12* together with the *Month* and *Year* features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New feature: lag 12\n",
    "data2[\"t-12\"] = data2[\"Passengers\"].shift(12)\n",
    "\n",
    "# Re-order columns for convenience\n",
    "data2 = data2[[\"t-12\", \"Month\", \"Year\", \"Passengers\"]].copy()\n",
    "\n",
    "# Show a few samples\n",
    "data2.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing values\n",
    "data2.dropna(inplace=True)\n",
    "\n",
    "# Show a few samples from the data\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the dataframe\n",
    "print(\"Data shape: {}\".format(data2.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to fit our fourth model; *t-12*, *Year* and *Month* are going to be the features and *Passengers* (differenced and log-transformed) the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train/set sets and create X/y arrays\n",
    "\n",
    "X_train_4, X_test_4, y_train_4, y_test_4 = train_test_split(data2, test_start_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit KNeighborsRegressor\n",
    "\n",
    "pipe4 = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),  # Scaling improves performance\n",
    "        (\"knn\", KNeighborsRegressor(n_neighbors=3, p=1, weights=\"distance\")),\n",
    "    ]\n",
    ")  # Hyperparameters: tuned with GridSearchCV\n",
    "pipe4.fit(X_train_4, y_train_4)\n",
    "\n",
    "# Compute predictions for train/test sets\n",
    "y_pred_tr_4 = pipe4.predict(X_train_4)\n",
    "y_pred_te_4 = pipe4.predict(X_test_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the third model, the target and the predictions are expressed as the month-to-month change in the number of passengers. We will invert differencing using the *invert_differencing* function from above.\n",
    "\n",
    "However, we need to pay attention to the following:\n",
    "* differencing threw away the first entry of the target\n",
    "* shifting the time-series forward by 12 periods threw away the next 12 observations in the target.\n",
    "\n",
    "We need to put these 13 (1 + 12) values back before calling the *cumsum* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve thrown away entries\n",
    "y0 = np.r_[data[\"Passengers\"][0], data1[\"Passengers\"][0:12]]  # length: 13\n",
    "\n",
    "# Define the number of samples in the train data (before differencing and lagging)\n",
    "len_train = len(y_train)\n",
    "\n",
    "# Target: Invert differencing\n",
    "y_train_4, y_test_4 = invert_differencing(y_train_4, y_test_4, y0, len_train)\n",
    "\n",
    "# Predictions: Invert differencing\n",
    "y_pred_tr_4, y_pred_te_4 = invert_differencing(y_pred_tr_4, y_pred_te_4, y0, len_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model performance\n",
    "print(\"Model 4\")\n",
    "print(\"-------\")\n",
    "print()\n",
    "print(\n",
    "    \"Train set - MAE score: {:.0f} passengers\".format(\n",
    "        model_error(y_train_4, y_pred_tr_4)\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Test set  - MAE score: {:.0f} passengers\".format(\n",
    "        model_error(y_test_4, y_pred_te_4)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "\n",
    "plot_predictions(\n",
    "    data,\n",
    "    y_train_4,\n",
    "    y_test_4,\n",
    "    y_pred_tr_4,\n",
    "    y_pred_te_4,\n",
    "    model_error(y_test_4, y_pred_te_4),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final comparison\n",
    "\n",
    "font = {\"fontname\": \"Arial\", \"size\": \"14\"}\n",
    "font_title = {\"fontname\": \"Arial\", \"size\": \"16\"}\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "labels = [\"Model 1\", \"Model 2\", \"Model 3\", \"Model 4\"]\n",
    "\n",
    "mae_values = [\n",
    "    model_error(y_test, y_pred_te),  # MAE :  model 1\n",
    "    model_error(y_test_2, y_pred_te_2),  # MAE :  model 2\n",
    "    model_error(y_test_3, y_pred_te_3),  # MAE :  model 3\n",
    "    model_error(y_test_4, y_pred_te_4),  # MAE :  model 4\n",
    "]\n",
    "\n",
    "xcor = np.arange(len(mae_values))\n",
    "plt.bar(xcor, mae_values, color=\"g\", edgecolor=\"black\")\n",
    "plt.xticks(xcor, labels, **font)\n",
    "plt.ylabel(\"MAE\", **font)\n",
    "plt.title(\"Model comparison\", **font_title)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "* Creating *meaningful* features is essential for building good machine learning models. In this exercise, we explored *date-time* and *lag* features and achieved good model performances.\n",
    "\n",
    "* In time-series data, transformations such as applying the logarithm and differencing can help to stabilize the *non-stationarity* in the variance and the mean, respectively, and improve model performance. However, there is no \"one-size-fits-all\" solution; other types of transformations (inverse, square root, cubic root, etc.) may work better depending on the time-series data and the model used.\n",
    "\n",
    "* Transformations need to be inverted to turn the observations back to their original scale. Log-transformations (natural base) can be reversed by applying the exponential function. Differencing can be reversed using the cumulative sum (*cumsum*) function.\n",
    "\n",
    "* The *KNeighborsRegressor* model is not the only Machine Learning model that can be used for time-series prediction! Feel free to experiment time-series forecasting with other models: LinearRegression, RandomForestRegressor, and neural networks!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
