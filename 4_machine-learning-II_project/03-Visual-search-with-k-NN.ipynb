{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the .npz file\n",
    "data = np.load('dataset_features.npz')\n",
    "\n",
    "# List all arrays within the .npz file\n",
    "print(data.files)\n",
    "\n",
    "# Access individual arrays by their names\n",
    "X_tr = data['trainset_features']\n",
    "y_tr = data['trainset_labels']\n",
    "\n",
    "X_val = data['validset_features']\n",
    "y_val = data['validset_labels']\n",
    "\n",
    "X_test = data['testset_features']\n",
    "y_test = data['testset_labels']\n",
    "files_test = data['testset_files']\n",
    "\n",
    "class_labels = data['class_labels']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create a k-NN pipeline\n",
    "knn_pipe = Pipeline(\n",
    "    [(\"scaler\", StandardScaler()), \n",
    "     (\"knn\", KNeighborsClassifier(n_neighbors=6))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# [Code adapted from the previous course]\n",
    "# Variable to store the results\n",
    "gs_results = []\n",
    "\n",
    "# Generate a set of k values\n",
    "k_values = np.arange(1, 50, step=1)\n",
    "\n",
    "# Grid search\n",
    "for k in k_values:\n",
    "    # Fit k-NN model\n",
    "    knn_pipe.set_params(knn__n_neighbors=k)\n",
    "    knn_pipe.fit(X_tr, y_tr)\n",
    "\n",
    "    # Save model and its performance on training/validation sets\n",
    "    gs_results.append(\n",
    "        {\n",
    "            \"k\": k,\n",
    "            \"train_accuracy\": knn_pipe.score(X_tr, y_tr),\n",
    "            \"valid_accuracy\": knn_pipe.score(X_val, y_val),\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Convert results to DataFrame\n",
    "gs_results = pd.DataFrame(gs_results)\n",
    "gs_results.sort_values(by=\"valid_accuracy\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the validation curves\n",
    "plt.plot(gs_results[\"k\"], gs_results[\"train_accuracy\"], label=\"train curve\")\n",
    "plt.plot(gs_results[\"k\"], gs_results[\"valid_accuracy\"], label=\"validation curve\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Low values of k, present high training accuracy, but in this region we're overfitting as can be seen by the accuracy gap between training and validation sets.\n",
    "\n",
    "For higher k, both training and validation sets accuracy decreases since we're now underfitting and increasing the model variance. \n",
    "\n",
    "Tuned classifier that maximizes the accuracy in validation set has k=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a k-NN pipeline\n",
    "knn_pipe_tuned = Pipeline(\n",
    "    [(\"scaler\", StandardScaler()), \n",
    "     (\"knn\", KNeighborsClassifier(n_neighbors=5))]\n",
    ")\n",
    "\n",
    "knn_pipe_tuned.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Classification report\n",
    "y_test_preds = knn_pipe_tuned.predict(X_test)\n",
    "\n",
    "print(classification_report(y_true=y_test, y_pred=y_test_preds, target_names=class_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision: Measures the accuracy of positive predictions for each class. It is the proportion of true positives out of all instances classified as that class. \n",
    "\n",
    "Recall: Measures the ability of the classifier to identify all true positives for each class. It is the proportion of true positives out of all actual instances of that class. \n",
    "\n",
    "Support: The number of actual instances in each class. Categories like bike (33), car (32), and motorcycle (25) have a higher number of samples, which typically leads to more reliable metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Define class labels\n",
    "class_labels = ['bike', 'car', 'motorcycle', 'other', 'truck', 'van']\n",
    "\n",
    "y_test_decoded = np.argmax(y_test, axis=1)\n",
    "y_pred_decoded = np.argmax(y_test_preds, axis=1)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test_decoded, y_pred_decoded)\n",
    "\n",
    "# Plot confusion matrix as heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix of Test Dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct classifications and nearest neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Find the correctly classified test images\n",
    "correct_indices = np.where(y_test_decoded == y_pred_decoded)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.load(files_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define image size and scaling\n",
    "image_size = (224, 224)\n",
    "batch_size = 32\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)  # Adjust rescaling if needed\n",
    "print('Testing set:')\n",
    "test_images = datagen.flow_from_directory('./test', target_size=image_size, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "def get_image_by_index(data_flow, desired_index):\n",
    "\n",
    "    test_images.reset()\n",
    "    \n",
    "    # Calculate batch number and index within the batch\n",
    "    batch_size = data_flow.batch_size\n",
    "    batch_number = desired_index // batch_size + 1\n",
    "    index_within_batch = desired_index % batch_size\n",
    "    \n",
    "    for _ in range(batch_number):\n",
    "        images, labels = next(data_flow)\n",
    "\n",
    "    image = images[index_within_batch]\n",
    "    label = labels[index_within_batch]\n",
    "\n",
    "    return image, label\n",
    "\n",
    "def get_image_by_index(fileset, desired_index):\n",
    "\n",
    "    image = \n",
    "    \n",
    "    image = images[index_within_batch]\n",
    "    label = labels[index_within_batch]\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select an image index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_index = correct_indices[10]\n",
    "print(f'Label of selected image: {class_labels[y_test_decoded[chosen_index]]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now find the nearest image entries to selected test imageset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Initialize and fit the NearestNeighbors model\n",
    "neighbors_model = NearestNeighbors(n_neighbors=3, algorithm='auto')\n",
    "neighbors_model.fit(X_test)\n",
    "\n",
    "nearest_distances, nearest_indices = neighbors_model.kneighbors(X_test[chosen_index,:].reshape(1, -1), n_neighbors=11)\n",
    "\n",
    "nearest_distances = nearest_distances[0]\n",
    "nearest_indices = nearest_indices[0]\n",
    "\n",
    "print(f'Nearest distances: {nearest_distances}')\n",
    "print(f'Nearest indices  : {nearest_indices}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the chosen test image\n",
    "fig, axes = plt.subplots(1, 11, figsize=(20, 3))\n",
    "\n",
    "chosen_image, chosen_label = get_image_by_index(test_images, chosen_index)\n",
    "axes[0].imshow(chosen_image)\n",
    "axes[0].set_title(\"Test Image\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "# Plot the 10 nearest neighbors from the training set\n",
    "for i, nearest_index in enumerate(nearest_indices[1:], start=1):\n",
    "       \n",
    "    nearest_image, nearest_label = get_image_by_index(test_images, nearest_index)\n",
    "    axes[i].imshow(nearest_image)\n",
    "    axes[i].set_title(f\"d: {nearest_distances[i]:.0f}\")  \n",
    "    axes[i].axis(\"off\")\n",
    "\n",
    "plt.suptitle(\"10 Nearest Neighbors of a Correctly Classified Test Image\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not needed!!! waiting for answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run several times the evaluation\n",
    "gs_results = []\n",
    "for run_idx in range(5):\n",
    "\n",
    "    # Grid search\n",
    "    for k in k_values:\n",
    "        # Fit k-NN model\n",
    "        knn_pipe.set_params(knn__n_neighbors=k)\n",
    "        knn_pipe.fit(X_tr, y_tr)\n",
    "\n",
    "        # Save model and its performance on training/validation sets\n",
    "        gs_results.append(\n",
    "            {\n",
    "                \"k\": k,\n",
    "                \"run_idx\": run_idx,\n",
    "                \"train_accuracy\": knn_pipe.score(X_tr, y_tr),\n",
    "                \"valid_accuracy\": knn_pipe.score(X_val, y_val),\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Convert results to DataFrame\n",
    "gs_results = pd.DataFrame(gs_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_results.groupby('k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing of statistics of different run results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group results by alpha value\n",
    "grouped = gs_results.groupby(\"k\")\n",
    "\n",
    "# Compute training/validation mean scores with std\n",
    "mean_tr = grouped.train_accuracy.mean()\n",
    "mean_val = grouped.valid_accuracy.mean()\n",
    "std_tr = grouped.train_accuracy.std()\n",
    "std_val = grouped.valid_accuracy.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot mean scores\n",
    "plt.plot(k_values, mean_tr, label=\"train\")\n",
    "plt.plot(k_values, mean_val, label=\"validation\")\n",
    "\n",
    "# Add marker for best score\n",
    "best_k = mean_val.idxmax()\n",
    "plt.scatter(best_k, mean_val.max(), marker=\"x\", c=\"red\", zorder=10)\n",
    "\n",
    "# Quantify variance with ±std curves\n",
    "plt.fill_between(k_values, mean_tr - std_tr, mean_tr + std_tr, alpha=0.2)\n",
    "plt.fill_between(k_values, mean_val - std_val, mean_val + std_val, alpha=0.2)\n",
    "plt.title(\"Best k: {} with {:.1f}% accuracy\".format(best_k, 100 * mean_val[best_k]))\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adsml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
