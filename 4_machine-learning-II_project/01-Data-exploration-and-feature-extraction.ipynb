{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Exploration and feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Image Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the documentation we see that:\n",
    "- image pixel values RGB in the range [0,1], following the common image input conventions. \n",
    "- image size fixed to 224 x 224 pixels\n",
    "\n",
    "We use this information to create a ImageDataGenerator to load the images from the provided folder structure. This will also process and return the categorical labels for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define image size and scaling\n",
    "image_size = (224, 224)\n",
    "batch_size = 32\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)  # Adjust rescaling if needed\n",
    "print('Training set:')\n",
    "trainset = datagen.flow_from_directory('./train', target_size=image_size, batch_size=batch_size, shuffle=False)\n",
    "print('Validation set:')\n",
    "validset = datagen.flow_from_directory('./valid', target_size=image_size, batch_size=batch_size, shuffle=False)\n",
    "print('Testing set:')\n",
    "testset = datagen.flow_from_directory('./test', target_size=image_size, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = list(validset.class_indices.keys())\n",
    "print(f'The classificaion labels are: \\n {class_labels}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting of few images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we print 5 images from the training set for each category. For this we iterate over the image generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_samples(dataset, category):\n",
    "\n",
    "    # we reset the iterator to make sure we cover all images    \n",
    "    dataset.reset()\n",
    "\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "    fig.suptitle(category)\n",
    "    \n",
    "    k=0\n",
    "    while k<5:\n",
    "\n",
    "        images, labels = next(dataset)\n",
    "    \n",
    "        for n,label in enumerate(labels):\n",
    "            if label[class_labels.index(category)] == 1:\n",
    "                axes[k].imshow(images[n]) \n",
    "                axes[k].axis('off')\n",
    "                k+=1\n",
    "                if k==5:\n",
    "                    break\n",
    "\n",
    "for category in class_labels:\n",
    "    plot_samples(trainset, category)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observation__\n",
    "\n",
    "- We observe that sometimes despite being in the same category images still exhibit a wide variety of pictures object. There's a big difference on perspective, lightning, set..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "class_dist = {'test': testset.classes, 'valid': validset.classes,'train': trainset.classes}\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 3))\n",
    "\n",
    "sns.histplot(trainset.classes, binwidth=1, binrange=(0,6), stat='probability', ax=axes[0])\n",
    "axes[0].set_title('Training set')\n",
    "axes[0].set_xticks(np.arange(len(class_labels))+0.5)\n",
    "axes[0].set_xticklabels(class_labels, rotation=45, ha='right')\n",
    "axes[0].set_ylim(0,0.25)\n",
    "\n",
    "sns.histplot(validset.classes, binwidth=1, binrange=(0,6), stat='probability', ax=axes[1])\n",
    "axes[1].set_title('Validation set')\n",
    "axes[1].set_xticks(np.arange(len(class_labels))+0.5)\n",
    "axes[1].set_xticklabels(class_labels, rotation=45, ha='right')\n",
    "axes[1].set_ylim(0,0.25)\n",
    "\n",
    "sns.histplot(testset.classes, binwidth=1, binrange=(0,6), stat='probability', ax=axes[2])\n",
    "axes[2].set_title('Testing set')\n",
    "axes[2].set_xticks(np.arange(len(class_labels))+0.5)\n",
    "axes[2].set_xticklabels(class_labels, rotation=45, ha='right')\n",
    "axes[2].set_ylim(0,0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observation__\n",
    "\n",
    "- All three image datasets share identical class distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color histogram of each category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll plot the accumulated color histogram for all images in the training dataset for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will compute the accumulated histograms for a given category\n",
    "\n",
    "def compute_histograms(dataset, category):\n",
    "\n",
    "    hist_r_total = np.zeros(256)\n",
    "    hist_g_total = np.zeros(256)\n",
    "    hist_b_total = np.zeros(256)\n",
    "\n",
    "    # we reset the iterator to make sure we cover all images\n",
    "    dataset.reset()\n",
    "\n",
    "    # Cycle through all image batches \n",
    "    while True:\n",
    "    \n",
    "        images, labels = next(dataset)\n",
    "\n",
    "        # Cycle through all images in current batch\n",
    "        for n,label in enumerate(labels):\n",
    "            if label[class_labels.index(category)] == 1:\n",
    "\n",
    "                # Calculate histograms for each channel (R, G, B) separately\n",
    "                hist_r, _ = np.histogram(images[n, :, :, 0].ravel()*256, bins=256, range=(0, 256))\n",
    "                hist_g, _ = np.histogram(images[n, :, :, 1].ravel()*256, bins=256, range=(0, 256))\n",
    "                hist_b, _ = np.histogram(images[n, :, :, 2].ravel()*256, bins=256, range=(0, 256))\n",
    "                \n",
    "                # Accumulate histograms\n",
    "                hist_r_total += hist_r\n",
    "                hist_g_total += hist_g\n",
    "                hist_b_total += hist_b\n",
    "\n",
    "        # Detect if this was the last batch\n",
    "        if len(labels) < batch_size:\n",
    "            break\n",
    "\n",
    "    # Normalize histogram\n",
    "    hist_r_total /= hist_r_total.sum()\n",
    "    hist_g_total /= hist_g_total.sum()\n",
    "    hist_b_total /= hist_b_total.sum()\n",
    "\n",
    "    return hist_r_total, hist_g_total, hist_b_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the accumulated color histograms\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 7))\n",
    "axes = axes.ravel()\n",
    "fig.suptitle('Accumulated Color Histogram for Training Dataset')\n",
    "\n",
    "for k, category in enumerate(class_labels):\n",
    "    \n",
    "    hist_r_total, hist_g_total, hist_b_total = compute_histograms(trainset, category)\n",
    "\n",
    "    axes[k].plot(hist_r_total, color='red', label='Red')\n",
    "    axes[k].plot(hist_g_total, color='green', label='Green')\n",
    "    axes[k].plot(hist_b_total, color='blue', label='Blue')\n",
    "\n",
    "    axes[k].set_title(category, y=0.9)\n",
    "    axes[k].set_xlabel('Pixel Intensity')\n",
    "    axes[k].set_ylabel('Frequency')\n",
    "    axes[k].set_ylim(0,0.014)\n",
    "    axes[k].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observation__:\n",
    "\n",
    "- There are some structures/shapes hint at differentiate betweeen some groups of categories, \n",
    "- However, it would be almost impossible to differentiate the 6 categories with just the color informatiom.\n",
    "- Additionally, here we observe the accumulated mean distribution of all images from a given category, but we don't have a view on the signal variance within each category. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction of High-Level Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll process our datasets through the MobileNet_v2 object detection model trained. This model detects high-level features and can serve a generic model for image classification. We start by importing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "# Create the image feature extractor\n",
    "model_url = \"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/5\"\n",
    "\n",
    "feature_extractor = hub.load(model_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we apply the model to our 3 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function applies the model to all images in a dataset \n",
    "def extract_features(dataset):\n",
    "    \n",
    "    features = tf.zeros((0, 1280))\n",
    "    labels = tf.zeros((0, 6))\n",
    "    \n",
    "    # we reset the iterator to make sure we start from first images\n",
    "    dataset.reset()\n",
    "\n",
    "    # cycle through batches\n",
    "    while True:\n",
    "        images_batch, labels_batch = next(dataset)\n",
    "        features = tf.concat([features, feature_extractor(images_batch)], axis=0)\n",
    "        labels = tf.concat([labels, labels_batch], axis=0)\n",
    "        \n",
    "        # detect last batch\n",
    "        if len(labels_batch) < batch_size:\n",
    "            break\n",
    "            \n",
    "    return features, labels\n",
    "\n",
    "trainset_features, trainset_labels = extract_features(trainset)\n",
    "validset_features, validset_labels = extract_features(validset)\n",
    "testset_features, testset_labels = extract_features(testset)\n",
    "\n",
    "print(f'Size of training set features: {trainset_features.shape}')\n",
    "print(f'Size of validation set features: {validset_features.shape}')\n",
    "print(f'Size of testing set features: {testset_features.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we save computed features to numpy .npz file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to an .npz file\n",
    "np.savez('dataset_features.npz', \n",
    "         trainset_features=trainset_features.numpy(),\n",
    "         validset_features=validset_features.numpy(),\n",
    "         testset_features=testset_features.numpy(),\n",
    "         trainset_labels=trainset_labels.numpy(),\n",
    "         validset_labels=validset_labels.numpy(),\n",
    "         testset_labels=testset_labels.numpy(),\n",
    "         class_labels=class_labels       \n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap of feature intensity for each category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next plot the feature value for all images in each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import decode_class\n",
    "\n",
    "fig, axes = plt.subplots(2,3,figsize=(15,10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Iterate over each category label\n",
    "for category_idx, category_name in enumerate(class_labels):\n",
    "    # Select features for the current category\n",
    "    category_features = trainset_features[decode_class(trainset_labels) == category_idx]\n",
    "    \n",
    "    # Check if there are samples in this category\n",
    "    sns.heatmap(category_features, cbar=True, ax=axes[category_idx])    \n",
    "    axes[category_idx].set_title(f'{category_name}')\n",
    "\n",
    "axes[3].set_xlabel('Feature Index')\n",
    "axes[4].set_xlabel('Feature Index')\n",
    "axes[5].set_xlabel('Feature Index')\n",
    "\n",
    "axes[0].set_ylabel('Sample Index')\n",
    "axes[3].set_ylabel('Sample Index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next repeat the exercise but this time, we average over all images in each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have a created a function util.decode_class() which decodes on-hot encoded class vectors\n",
    "\n",
    "# Initialize a dictionary to store accumulated feature intensities\n",
    "accumulated_features = {}\n",
    "\n",
    "# Accumulate feature values for each category\n",
    "for category_idx, category_name in enumerate(class_labels):\n",
    "\n",
    "    # Select features for the current category and sum them across all samples\n",
    "    category_features = trainset_features[decode_class(trainset_labels) == category_idx]\n",
    "    accumulated_features[category_name] = np.mean(category_features, axis=0)\n",
    "\n",
    "# Plot heatmap for each category's accumulated features\n",
    "plt.figure(figsize=(14, 4))\n",
    "sns.heatmap([accumulated_features[category] for category in class_labels], \n",
    "            cbar=True, yticklabels=class_labels)\n",
    "plt.title('Accumulated Feature Intensity for Each Category')\n",
    "plt.xlabel('Feature Index')\n",
    "plt.ylabel('Category')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observation__:\n",
    "\n",
    "- In the bottom plot, the intensities across the x-axis (features) indicate that some features contribute more strongly to the classification of certain categories (brighter bands in certain regions). This can be seen as a signature for each category which will be used by the models of next section to create a classifier for our objects/classes.\n",
    "\n",
    "- In the top plots, the variability along the y-axis (samples) indicate  how different images in the same category can activate slightly different high-level features. \n",
    "\n",
    "- It's interesting to see how for the category 'other' which by definition can contain different types of objects there seems to be almost repeating vertical structure among the different samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top features of each category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll obtain the top valued high-level features for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store mean values for each category\n",
    "top_features = {}\n",
    "\n",
    "# Calculate mean feature values for each category and identify top 5 features\n",
    "for category_label, category_name in enumerate(class_labels):\n",
    "    \n",
    "    # Select features for the current category\n",
    "    category_features = trainset_features[decode_class(trainset_labels) == category_label]\n",
    "    \n",
    "    # Calculate mean of each feature across all samples in the category\n",
    "    feature_means = np.mean(category_features, axis=0)\n",
    "    \n",
    "    # Find top 5 features with the highest mean values\n",
    "    top_5_indices = np.argsort(feature_means)[-5:]\n",
    "    top_5_features = [(idx, feature_means[idx]) for idx in top_5_indices]\n",
    "    \n",
    "    # Store top features in the dictionary\n",
    "    top_features[category_name] = top_5_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the top 5 features for each category\n",
    "for category, features in top_features.items():\n",
    "    print(f\"Top 5 features for '{category}':\")\n",
    "    \n",
    "    for feature_idx, mean_value in reversed(features):\n",
    "        print(f\" {feature_idx:5d}: Mean Value = {mean_value:.3f}\")\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category, feature_tuple in top_features.items():\n",
    "    print(f\"{category:}: {[feature_idx for feature_idx, _ in feature_tuple]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Extract feature indices from all categories\n",
    "all_feature_indices = [feature_idx for category in top_features.values() for feature_idx, _ in category]\n",
    "\n",
    "print(\"Repeated features:\")\n",
    "pd.DataFrame(all_feature_indices).value_counts().head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observation:__\n",
    "\n",
    "- The top 5 high-level features for each category are almost unique\n",
    "- Only 3 features (183, 1022 and 580) are repeated among two categories\n",
    "- Feature 183  shows in 'bike' and 'car'\n",
    "- Feature 1022 shows in 'truck' and 'van'\n",
    "- Feature 580  shows in 'truck' and 'other'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adsml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
