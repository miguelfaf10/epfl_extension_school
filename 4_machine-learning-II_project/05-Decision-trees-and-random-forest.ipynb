{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import get_image_by_index, decode_class\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the .npz file\n",
    "data = np.load('dataset_features.npz')\n",
    "\n",
    "# List all arrays within the .npz file\n",
    "print(data.files)\n",
    "\n",
    "# Access individual arrays by their names\n",
    "X_train = data['trainset_features']\n",
    "y_train = data['trainset_labels']\n",
    "\n",
    "X_val = data['validset_features']\n",
    "y_val = data['validset_labels']\n",
    "\n",
    "X_test = data['testset_features']\n",
    "y_test = data['testset_labels']\n",
    "\n",
    "class_labels = data['class_labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree with depth of 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier(criterion=\"gini\", max_depth=3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit decision tree\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "print('Model Accuracy:')\n",
    "print(f'On train set: {dtree.score(X_train, y_train):.3f}')\n",
    "print(f'On valid set: {dtree.score(X_val, y_val):.3f}')\n",
    "print(f'On test  set: {dtree.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(16, 14))\n",
    "plot_tree(\n",
    "    dtree,\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    proportion=True,\n",
    "    class_names=class_labels,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning of model depth (using cross-validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_crossval = np.concatenate((X_train, X_val), axis=0)\n",
    "y_crossval = decode_class(np.concatenate((y_train, y_val), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define grid of regularization strengths to test\n",
    "param_grid = {\n",
    "    'max_depth': np.linspace(1, 12, 12)  # Test values from 10^-4 to 10^4\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=dtree,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',  # Metric for evaluating models\n",
    "    cv=5,                # 5-fold cross-validation\n",
    "    n_jobs=-1,           # Use all available processors\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# Perform grid search\n",
    "grid_search.fit(X_crossval, y_crossval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Extract results from the GridSearchCV object\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "# Select relevant columns for interpretation\n",
    "results_df = results[\n",
    "    [\n",
    "        'param_max_depth',  # Regularization strength parameter\n",
    "        'mean_train_score',  # Mean training score across folds\n",
    "        'std_train_score',  # Standard deviation of training score across folds\n",
    "        'mean_test_score',  # Mean validation (test) score across folds\n",
    "        'std_test_score'  # Standard deviation of validation score across folds\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Sort by the validation score for better interpretability\n",
    "results_df = results_df.sort_values(by='mean_test_score', ascending=False)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have metrics recorded during training, such as accuracy or loss\n",
    "# Example data (replace with actual metrics from your training process)\n",
    "\n",
    "results_df = results_df.sort_values(by='param_max_depth')\n",
    "\n",
    "param_max_depth = results_df['param_max_depth'].to_numpy()\n",
    "train_scores_mean = results_df['mean_train_score'].to_numpy()\n",
    "val_scores_mean = results_df['mean_test_score'].to_numpy()\n",
    "train_scores_std = results_df['std_train_score'].to_numpy()\n",
    "val_scores_std = results_df['std_test_score'].to_numpy()\n",
    "\n",
    "# Plot the curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(param_max_depth, train_scores_mean, label=\"Training Accuracy\", marker=\"o\")\n",
    "plt.plot(param_max_depth, val_scores_mean, label=\"Validation Accuracy\", marker=\"o\")\n",
    "#plt.fill_between(param_max_depth, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.2)\n",
    "#plt.fill_between(param_max_depth, val_scores_mean - val_scores_std, val_scores_mean + val_scores_std, alpha=0.2)\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "plt.xlabel(\"C Parameter\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observee that at depth>=3 the model starts to overfit. Nevertheless the optimal accuracy in the validation sets corresponds to depth=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree.set_params(max_depth=5)\n",
    "\n",
    "# Fit decision tree\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "print('Model Accuracy:')\n",
    "print(f'On train set: {dtree.score(X_train, y_train):.3f}')\n",
    "print(f'On valid set: {dtree.score(X_val, y_val):.3f}')\n",
    "print(f'On test  set: {dtree.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which slightly increases the model accuracy also on the test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two step model with PCA then random forest (re-check this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the pipeline with PCA and Decision Tree\n",
    "pipeline = Pipeline([\n",
    "    ('pca', PCA()),  # PCA step\n",
    "    ('dtree', DecisionTreeClassifier())  # Decision tree step\n",
    "])\n",
    "\n",
    "# Define a grid for PCA components and decision tree parameters\n",
    "param_grid = {\n",
    "    'pca__n_components': [5, 10, 15, 20],  # Number of PCA components to test\n",
    "    'dtree__max_depth': [5, 10, 15, None]  # Decision tree depths to test\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit the pipeline to the data\n",
    "grid_search.fit(X_crossval, y_crossval)\n",
    "\n",
    "# Get the best parameters and model\n",
    "best_pipeline = grid_search.best_estimator_\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best Cross-Validated Accuracy: {grid_search.best_score_}\")\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "test_accuracy = best_pipeline.score(X_test, decode_class(y_test))\n",
    "print(f\"Test Accuracy with PCA: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define Random Forest model\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "\n",
    "# Define parameter grid for tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100, 200],  # Number of trees to test\n",
    "    'max_depth': [5, 10, 20, None]  # Tree depths to test\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search_rf = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "grid_search_rf.fit(X_crossval, y_crossval)\n",
    "\n",
    "# Best parameters and model\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "print(f\"Best Parameters: {grid_search_rf.best_params_}\")\n",
    "print(f\"Best Cross-Validated Accuracy: {grid_search_rf.best_score_}\")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_test_pred = best_rf.predict(X_test)\n",
    "rf_test_accuracy = accuracy_score(decode_class(y_test), y_test_pred)\n",
    "print(f\"Test Accuracy with Random Forest: {rf_test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances\n",
    "feature_importances = best_rf.feature_importances_\n",
    "\n",
    "# Create a DataFrame to store feature names and their importance scores\n",
    "features_df = pd.DataFrame({\n",
    "    'Feature': np.arange(X_crossval.shape[1]),  # Replace with feature names if X_train is a DataFrame\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort features by importance\n",
    "top_features = features_df.sort_values(by='Importance', ascending=False).head(5)\n",
    "top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualize the top 5 important features\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.bar(range(5), top_features['Importance'])\n",
    "plt.xticks(range(5), top_features['Feature'])\n",
    "plt.title('Top 5 Important Features in Random Forest')\n",
    "plt.ylabel('Importance Score')\n",
    "plt.xlabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differences arise due to the models’ nature—linear vs. nonlinear and how they handle feature interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adsml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
