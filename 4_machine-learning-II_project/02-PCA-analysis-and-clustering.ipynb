{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. PCA analysis and Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading of extracted high-level features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the .npz file\n",
    "data = np.load('dataset_features.npz')\n",
    "\n",
    "# List all arrays within the .npz file\n",
    "print(data.files)\n",
    "\n",
    "# Access individual arrays by their names\n",
    "trainset_features = data['trainset_features']\n",
    "trainset_labels = data['trainset_labels']\n",
    "testset_features = data['testset_features']\n",
    "testset_labels = data['testset_labels']\n",
    "\n",
    "\n",
    "class_labels = data['class_labels']\n",
    "\n",
    "X = trainset_features\n",
    "y = trainset_labels\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_rescaled = scaler.fit_transform(X)\n",
    "\n",
    "# Create PCA transformer\n",
    "pca = PCA(n_components=None)\n",
    "\n",
    "# Fit model to rescaled data\n",
    "pca.fit(X_rescaled)\n",
    "\n",
    "pve = pca.explained_variance_ratio_\n",
    "print(f'Total number of PCA components  : {len(pve)}')\n",
    "print(f'Value of first 5 PCA components : {pve[:5]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scree plot of PCA components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(13,5))\n",
    "\n",
    "pca_component = np.arange(len(pve))\n",
    "plt.bar(pca_component, pve)\n",
    "plt.xticks(pca_component[::5], rotation=90)\n",
    "\n",
    "# Add cumulative sum\n",
    "pve_cumsum = np.cumsum(pve)\n",
    "plt.step(\n",
    "    pca_component,\n",
    "    pve_cumsum,  \n",
    ")\n",
    "\n",
    "# Add labels\n",
    "plt.xlabel(\"principal component\")\n",
    "plt.ylabel(\"proportion of variance explained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var_percent in np.arange(10,100,10):\n",
    "\n",
    "    print(f'Components explaining {var_percent}% of variance: {np.argmax(pve_cumsum > var_percent/100)+1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observation:__\n",
    "- There are a total of 280 PCA components which is equal to the number of samples in the training set\n",
    "- For explaining 100% of the variance in the dataset we obviously need all the 280 components\n",
    "- And with just 2 components we can already explain 10% of the variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA(2) basis and k-means clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by transforming (projecting) the trainset data into the basis formed by 2 first PCA components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca2 = pca.transform(X_rescaled)[:,:2]    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also apply the k-means clustering algorithm on these 2 components of the PCA-transformed data, with the numbers of clusters equal to the number of categories we want to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=6, random_state=42)\n",
    "\n",
    "# Compute k-means\n",
    "kmeans.fit(X_pca2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we show the both data transformations into two side-by-side plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import decode_class\n",
    "\n",
    "fig, axes = plt.subplots(1,2,figsize=(16,8))\n",
    "\n",
    "# Plot each category on the 2D PCA space\n",
    "for label_idx, label in enumerate(class_labels):\n",
    "    # Images of this digit\n",
    "    sample_idx = decode_class(trainset_labels) == label_idx\n",
    "\n",
    "    # Plot images\n",
    "    axes[0].scatter(\n",
    "        X_pca2[sample_idx, 0],\n",
    "        X_pca2[sample_idx, 1],\n",
    "        s=20, \n",
    "        label = label\n",
    "    )\n",
    "axes[0].set_aspect('equal')\n",
    "axes[0].set_xlabel('PCA component 1')\n",
    "axes[0].set_ylabel('PCA component 2')\n",
    "axes[0].set_title('PCA components of each class')\n",
    "axes[0].legend()\n",
    "\n",
    "\n",
    "\n",
    "# Plot each cluster also in the 2D PCA space\n",
    "for cluster in [2, 4, 5, 0, 3, 1]:\n",
    "    # Get points in this cluster\n",
    "    idx = kmeans.labels_ == cluster\n",
    "    x1, x2 = X_pca2[idx, 0], X_pca2[idx, 1]\n",
    "\n",
    "    # Plot points\n",
    "    axes[1].scatter(x1, x2, s=20, label=f\"cluster {cluster}\")\n",
    "\n",
    "    # Plot centroid\n",
    "    centroid = kmeans.cluster_centers_[cluster]\n",
    "    axes[1].plot(centroid[0], centroid[1], marker=\"*\", color=\"black\", markersize=18)\n",
    "\n",
    "axes[1].set_aspect('equal')\n",
    "axes[1].set_xlabel(\"PCA component 1\")\n",
    "axes[1].set_ylabel(\"PCA component 2\")\n",
    "axes[1].set_title('k-means clustering of PCA components')\n",
    "axes[1].legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observation:__\n",
    "\n",
    "- In the left plot, we see that just the first two PCA components aleady allows for a good separation of some categories.\n",
    "    - 'bike', 'van', and 'car' form relatively distinct clusters in the 2D PCA projection, suggesting that the first two principal components capture significant variance for these classes.\n",
    "    - Other classes (e.g., 'truck' and 'other') appear to overlap more, indicating that the first two components may not fully separate these categories.\n",
    "\n",
    "- By comparing the right plot clusters with the true categorization shown in the left plot we observed that:\n",
    "    - The 'bike', 'car' and 'van' categories aligns relatively well with the k-means clusters 2, 4 and 1 respectively\n",
    "    - Cluster 5 seems to capture about half of the 'motorcyle' category\n",
    "    - For the 'other' and 'truck' categories, these are grouped together into cluster 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA transformation of test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_test_rescaled = scaler.fit_transform(testset_features)\n",
    "\n",
    "# Transform the test dataset to the 2D PCA space\n",
    "test_pca2 = pca.transform(X_test_rescaled)[:,:2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we overlap the test samples, scaled and projected in the 2D PCA space, with the previously shown train data. The color of each datapoint of these datasamples correctly corresponds to the true categories. We use a star \"*\" marker to differentiate the test set samples from the train set samples (represented by a circle)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for label_idx, label in enumerate(class_labels):\n",
    "    \n",
    "    sample_idx = decode_class(trainset_labels) == label_idx\n",
    "\n",
    "    # Plot images\n",
    "    plt.scatter(\n",
    "        X_pca2[sample_idx, 0],\n",
    "        X_pca2[sample_idx, 1],\n",
    "        s=10, \n",
    "        label = label\n",
    "    )\n",
    "    \n",
    "plt.gca().set_aspect('equal')\n",
    "plt.xlabel('PCA component 1')\n",
    "plt.ylabel('PCA component 2')\n",
    "plt.title('PCA components of the train set (cirlces) and test set (stars)')   \n",
    "plt.legend()\n",
    "\n",
    "plt.gca().set_prop_cycle(None)\n",
    "    \n",
    "for label_idx, label in enumerate(class_labels):\n",
    "    \n",
    "    sample_idx = decode_class(testset_labels) == label_idx\n",
    "\n",
    "    # Plot images\n",
    "    plt.scatter(\n",
    "        test_pca2[sample_idx, 0],\n",
    "        test_pca2[sample_idx, 1],\n",
    "        s=80, \n",
    "        label = label,\n",
    "        marker= '*',\n",
    "    )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observation:__\n",
    "\n",
    "- By counting the star points that are located in regions where the predominant train samples correspond to a different category, we estimated that around 3 to 6 samples (out of 50) wil be hard to classify"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adsml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
